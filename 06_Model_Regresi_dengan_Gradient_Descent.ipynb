{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06. Model Regresi dengan Gradient Descent",
      "provenance": [],
      "authorship_tag": "ABX9TyNhIEwKGeK53NRrETiTCMBS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiorjioo/KelasMahir-3.0/blob/main/06_Model_Regresi_dengan_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9594qsG4uflo"
      },
      "source": [
        "Bismillah\n",
        "\n",
        "\n",
        "*   Model Regresi Linear Sederhana\n",
        "*   Metode Gradient Descent\n",
        "*   Contoh Perhitungan Manual Regresi Linear dengan Gradient Descent\n",
        "*   Regresi Linear Python From Scratch\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA-cXnsyuzKo"
      },
      "source": [
        "## **Model Regresi Linear Sederhana**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9WW1Hfwu4xI"
      },
      "source": [
        "Regresi Linear adalah metode untuk mendefinisikan hubungan linear antara variabel dependen Y dan variabel\n",
        "independen X. Secara sederhana dapat dituliskan dalam formula berikut:\n",
        "\n",
        "$Y_{i} = b_{0} + b_{1}X_{i} + ε_{i}$\n",
        "\n",
        "Yang mana adalah $Y_{i}$ variabel dependen, $X_{i}$ adalah variabel independen, $ε$ adalah kesalahan acak, $b_{0}$ disebut\n",
        "sebagai intercept dan $b_{1}$ disebut sebagai koefisien regresi yang dapat diestimasi berdasarkan data $Y_{i}$ dan $X_{i}$\n",
        "yang diberikan. Koefisien $b_{0}$ juga biasa disebut sebagai bias. Tujuan utama dari model ini adalah untuk\n",
        "mengambarkan garis linear dengan kesesuaian terbaik(best fit) antara X dan Y yang mengestimasi hubungan\n",
        "antara X dan Y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMrqwuhvvovv"
      },
      "source": [
        "## **Metode Gradient Descent**\n",
        "\n",
        "Sebelumnya kita telah membahas tentang estimasi hubungan antara X dan Y pada sebuah garis. Misalnya, kita\n",
        "sediakan input dan output sampel, kemudian kita memplot titik titik data ini pada grafik 2 dimensi, maka akan\n",
        "dihasilkan grafik seperti di bawah ini:\n",
        "\n",
        "![picture](https://raw.githubusercontent.com/jokoeliyanto/Channel-Hobi-Data/main/Model%20Machine%20Learning%20dari%20Dasar(From%20Scratch)%20Python/Header%20Image/Data%20Regresi.png)\n",
        "\n",
        "Garis merah pada grafik adalah hubungan sesungguhnya yang ingin disetimasi. Kita berusaha untuk\n",
        "meminimalkan kesalahan model yang kita bangun. Garis ini adalah garis yang paling tepat menggambarkan\n",
        "hubungan antara data X dan Y dengan melewati sebagian besar titik data dan memiliki kesalahan yang paling\n",
        "minimal. Kesalahan ini berupa jarak titik data ke garis estimasi model ini. Secara konseptual kesalahan ini\n",
        "diilustrasikan pada gambar di bawah ini.\n",
        "\n",
        "![picture](https://raw.githubusercontent.com/jokoeliyanto/Channel-Hobi-Data/main/Model%20Machine%20Learning%20dari%20Dasar(From%20Scratch)%20Python/Header%20Image/LS.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0umJPHPNv8Ya"
      },
      "source": [
        "Dan kesalahan total model linier adalah jumlah kesalahan dari setiap titiknya, yaitu:\n",
        "\n",
        "\\begin{align*}\n",
        "\\sum_{i=1}^{n} ε_{i}^{2}\n",
        "\\end{align*}\n",
        "\n",
        "$εi$ = Jarak antara garis ke titik data ke-i\n",
        "\n",
        "$n$ = Jumlah total titik data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vafMd0etv_VQ"
      },
      "source": [
        "Formula di atas diperoleh dari:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "y_{i} = b_{0} + b_{1}.x_{i} + ε_{i}\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "ε_{i} = y_{i} - b_{0} - b_{1}.x_{i}\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\\sum_{i=1}^{n} ε_i^{2} = \\sum_{i=1}^{n} (y_{i} - b_{0} - b_{1}.x_{i}) ^{2}\n",
        "\\end{align}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtNVFRHAwA5F"
      },
      "source": [
        "======================================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO3v9Yh1wDPA"
      },
      "source": [
        "Jika pada pembahasan sebelumnya kita mengestimasi koefisien $b_{0}$ dan $b_{1}$ menggunakan metode OLS. Maka\n",
        "kita akan menggunakan metode lain yaitu **Gradient Descent**. Ada catatan penting ketika kita menerapkan\n",
        "metode OLS saat ingin mengestimasi nilai parameter koefisien $b_{0}$ dan $b_{1}$, yaitu ketika nilai turunan fungsi eror\n",
        "diasumsikan sama dengan nol saat mencapai nilai minimum.\n",
        "\n",
        "Faktanya, nilai minimum Global yang dicari tidak selalu terjadi ketika turunan pertamanya sama dengan nol.\n",
        "Inilah yang menjadi ide dasar dari metode selanjutnya yaitu Gradient Descent. Alih-alih langsung\n",
        "mengasumsikan turunan pertama dari fungsi eror terhadap parameter adalah sama dengan nol. Maka metode\n",
        "ini justru menggunakan formula turunan parsial pertama dari fungsi eror untuk memperbaharui nilai estimasi\n",
        "parameter koefisien $b_{0}$ dan $b_{1}$. Proses ini diulang(iterasi) hingga memperoleh kriteria yang diharapkan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIS646z5wbQE"
      },
      "source": [
        "Pembaharuan dari nilai parameter $b_{0}$ dan $b+1$ adalah sebagai berikut:\n",
        "\n",
        "\\begin{align}\n",
        "b_{0} (baru) = b_{0}(lama) - \\Delta b_{0} \\times tk  \\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "b_{1} (baru) = b_{1}(lama) - \\Delta b_{1} \\times tk  \\end{align}\n",
        "\n",
        "yang mana $tk$ adalah tingkat ketelitian pembelajaran model ML atau learning rate ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZF8yoUnxorw"
      },
      "source": [
        "Pada notebook ini kita juga akan menggunakan fungsi eror(Cost) yang berbeda. Yaitu **MSE(Mean Square\n",
        "Error)** dengan formula seperti di bawah ini.\n",
        "\n",
        "\\begin{align}\n",
        "Cost = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - ( b_{0} + b_{1}.x_{i})) ^{2}\n",
        "\\end{align}\n",
        "\n",
        "$\\Delta b_{0}$ dan $ \\Delta b_{1}$ adalah nilai perubahan parameter $b_0$ dan $b_1$ yang diperoleh dari turunan parsial pertama fungsi\n",
        "Cost yaitu sebagai berikut:\n",
        "\n",
        "$\\Delta b_{0} = \\frac{\\delta Cost}{\\delta b_0} $\n",
        "\n",
        "$= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_{i} - ( b_{0} + b_{1}.x_{i}))(-1)\n",
        "$\n",
        "\n",
        "$ =  \\frac{-2}{n} \\sum_{i=1}^{n} (y_{i} - ( b_{0} + b_{1}.x_{i}))$\n",
        "\n",
        "$ = \\frac{-2}{n}\\sum_{i=1}^{n} (y-y') $\n",
        "\n",
        " \\\\\n",
        "\n",
        "$\\Delta b_{1} = \\frac{\\delta Cost}{\\delta b_1} $\n",
        "\n",
        "$= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_{i} - ( b_{1} + b_{1}.x_{i}))(-1)x\n",
        "$\n",
        "\n",
        "$ =  \\frac{-2}{n} \\sum_{i=1}^{n} (y_{i} - x . (b_{0} + b_{1}.x_{i}))$\n",
        "\n",
        "$ = \\frac{-2}{n}\\sum_{i=1}^{n} x.(y-y') $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R8i6w031tPa"
      },
      "source": [
        "Sehingga pembaruan nilai parameter b dan adalah sebagai berikut:\n",
        "\n",
        "\\begin{align}\n",
        "b_0(baru) = b_0(lama) - \\frac{-2}{n}\\sum_{i=1}^{n} x.(y-y') \\times tk\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "b_1(baru) = b_1(lama) - \\frac{-2}{n}\\sum_{i=1}^{n} x.(y-y') \\times tk\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B8Qgtyd2Iqi"
      },
      "source": [
        "## **Contoh Perhitungan Manual Regresi Linear dengan Gradient Descent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25IiW1q2ODw"
      },
      "source": [
        "Diketahui data X dan Y adalah sebagai berikut(Y=2X-1):\n",
        "\n",
        "\\begin{matrix} \n",
        "X & Y \\\\\n",
        "1 & 1 \\\\\n",
        "3 & 5 \\\\\n",
        "5 & 9 \\\\\n",
        "6 & 11 \\\\\n",
        "7 & 13 \\\\\n",
        "8 & 15 \\\\\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqK78BfS2ybt"
      },
      "source": [
        "Berikut adalah proses menghitung model Regresi Linear dari data di atas:\n",
        "\n",
        "Nilai awal: \\\\\n",
        "$tk$ = 0.01 \\\\\n",
        "$b_0$ = 0 \\\\\n",
        "$b_1$ = 1 \\\\\n",
        "$n$ =  6 \\\\\n",
        " \\\\\n",
        "\n",
        "$\n",
        "\\begin{matrix} \n",
        "b_0 + b_1 \\times X_i & y' \\\\\n",
        "0 + 1(1) & 1 \\\\\n",
        "0 + 1(3) & 3 \\\\\n",
        "0 + 1(5) & 5 \\\\\n",
        "0 + 1(6) & 6 \\\\\n",
        "0 + 1(7) & 7 \\\\\n",
        "0 + 1(8) & 8 \\\\\n",
        "\\end{matrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDCQU9FX3N1j"
      },
      "source": [
        "***Iterasi/ Epochs 1***\n",
        "\n",
        "**[1] Menghitung perubahan parameter $\\Delta b_0$ dan $\\Delta b_1$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gLhM5zK4IXb"
      },
      "source": [
        "Menghitung perubahan $\\Delta b_0:$\n",
        "\n",
        "$\\Delta b_0 = \\frac{-2}{n}\\sum_{i=1}^{n} (y-y') \\\\\n",
        "= \\frac{-2}{6}[(1 − 1) + (5 − 3) + (9 − 5) + (11 − 6) + (13 − 7) + (15 − 8)] \\\\\n",
        "= \\frac{-2}{6}24 \\\\\n",
        "= -8$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulnk0qVV40TC"
      },
      "source": [
        "Menghitung perubahan $\\Delta b_1:$\n",
        "\n",
        "$\\Delta b_1 = \\frac{-2}{n}\\sum_{i=1}^{n} (y-y') \\\\\n",
        "= \\frac{-2}{6}[1.(1 − 1) + 3.(5 − 3) + 5.(9 − 5) + 6.(11 − 6) + 7.(13 − 7) + 8.(15 − 8)] \\\\\n",
        "= \\frac{-2}{6}154 \\\\\n",
        "= −51.333$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrpEDxwt5JRp"
      },
      "source": [
        "**[2] Menghitung parameter $b_0$ dan $b_1$ yang baru**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WugBbosw5cFg"
      },
      "source": [
        "$\n",
        "\\begin{align}\n",
        "b_{0} (baru) = b_{0}(lama) - \\Delta b_{0} \\times tk  \\\\\n",
        "= 0 - (-8) \\times 0.01 \\\\\n",
        "= 0.08 \\end{align}\n",
        "$\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "b_{1} (baru) = b_{1}(lama) - \\Delta b_{1} \\times tk  \\\\\n",
        "= 0 - (−51.333) \\times 0.01 \\\\\n",
        "= 1.513 \\end{align}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmY9SLTw9ube"
      },
      "source": [
        "**[3] Menghitung Nilai Cost/ Error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5ZzkUBi-GD8"
      },
      "source": [
        "$\n",
        "Cost = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - ( b_{0} + b_{1}.x_{i})) ^{2} \\\\\n",
        "= \\frac{1}{6} [(1 − 1)^2 + (5 − 3)^2 + (9 − 5)^2 + (11 − 6)^2 + (13 − 7)^2 + (15 − 8)^2 ] \\\\\n",
        "= 21.666\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxwsIHx6-aGK"
      },
      "source": [
        "***Iterasi/ Epochs 2***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCqBitR5-gdw"
      },
      "source": [
        "$\n",
        "\\begin{matrix} \n",
        "b_0 + b_1 \\times X_i & y' \\\\\n",
        "0.08 + 1.513(1) & 1.59333333 \\\\\n",
        "0.08 + 1.513(3) & 4.62 \\\\\n",
        "0.08 + 1.513(5) & 7.64666667 \\\\\n",
        "0.08 + 1.513(6) & 9.16 \\\\\n",
        "0.08 + 1.513(7) & 10.67333333 \\\\\n",
        "0.08 + 1.513(8) & 12.18666667 \\\\\n",
        "\\end{matrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBek4iIh-1Zm"
      },
      "source": [
        "**[1] Menghitung perubahan parameter $\\Delta b_0$ dan $\\Delta b_1$**\n",
        "\n",
        "Menghitung perubahan $\\Delta b_0: $\n",
        "\n",
        "$\\Delta b_0 = \\frac{-2}{n}\\sum_{i=1}^{n} (y-y') \\\\\n",
        "= \\frac{-2}{6}[(1 − 1.59333333) + (5 − 4.62) + (9 − 7.64666667) + (11 − 9.16) + (13 − 10.67333333) + (15 − 12.18666667)] \\\\\n",
        "= −2.706$ \n",
        "\n",
        " \\\\\n",
        "\n",
        "Menghitung perubahan $\\Delta b_1: $\n",
        "\n",
        "$\\Delta b_1 = \\frac{-2}{n}\\sum_{i=1}^{n} (y-y') \\\\\n",
        "= \\frac{-2}{6}[1.(1 − 1.59333333) + 3.(5 − 4.62) + 5.(9 − 7.64666667) + 6.(11 − 9.16) + 7.(13 − 10.67333333) + 8.(15 − 12.18666667)] \\\\\n",
        "= −19.048$ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ons_PSBWAB1l"
      },
      "source": [
        "**[2] Menghitung parameter $b_0$ dan $b_1$ yang baru**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RGaFp2bACXO"
      },
      "source": [
        "$\n",
        "\\begin{align}\n",
        "b_{0} (baru) = b_{0}(lama) - \\Delta b_{0} \\times tk  \\\\\n",
        "= 0.08 + (−2.706) \\times 0.01 \\\\\n",
        "= 0.107 \\end{align}\n",
        "$\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "b_{1} (baru) = b_{1}(lama) - \\Delta b_{1} \\times tk  \\\\\n",
        "= 1.513 + (−19.048)\\times 0.01 \\\\\n",
        "= 1.703 \\end{align}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZgprB4tAV9A"
      },
      "source": [
        "**[3] Menghitung Nilai Cost/ Error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddw7zsftAW_7"
      },
      "source": [
        "$\n",
        "Cost = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - y'_i) ^{2} \\\\\n",
        "= \\frac{1}{6} [(1 − 1.59333333)^2 + (5 − 4.62)^2 + (9 − 7.64666667)^2 + (11 − 9.16)^2 + (13 − 10.67333333)^2 + (15 − 12.18666667)^2] \\\\\n",
        "= 3.173\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK0AOvJFA1SK"
      },
      "source": [
        "Menggunakan metode Gradient Descent nilai eror pada iterasi pertama adalah 21.666 dan nilai eror pada\n",
        "iterasi kedua adalah 3.173. Hal itu berarti metode ini berhasil memperbaiki eror dari model regresi linear pada\n",
        "setiap iterasinya. Proses iterasi ini berjalan hingga suatu kriteria dipenuhi. Beberapa kriteria henti yang bisa\n",
        "dipakai:\n",
        "\n",
        "\n",
        "\n",
        "1.  Ketika jumlah iterasi tertentu telah dicapai\n",
        "2.   Ketika nilai eror tertentu telah dicapai\n",
        "3.  Ketika selisi nilai eror tertentu antara iterasi terakhir dengan iterasi sebelumnya telah dicapai\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpNAIIrxA_kq"
      },
      "source": [
        "## **Regresi Linear Python From Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsaX5hZ2BESa"
      },
      "source": [
        "### **Membangun Model Regresi Linear**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z7FA8FNBKtc"
      },
      "source": [
        "Pertama, import library python yang dibutuhkan yaitu: \n",
        "\n",
        "\n",
        "*   Numpy\n",
        "*   Pandas\n",
        "*   Matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DaTaxmtBVl0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNLefWTBX0n"
      },
      "source": [
        "Untuk memahami konsep, kita akan menggunakan data X dan Y seperti yang kita tunjukkan pada proses\n",
        "penghitungan manual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxDBndVrBa97"
      },
      "source": [
        "X_train=np.array([[1], [3], [5], [6], [7], [8]])\n",
        "y_train=np.array([1, 5, 9, 11, 13, 15])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdZ080rvBb3s"
      },
      "source": [
        "Kode di bawah ini dibangun menggunakan kriteria bahwa program akan berhenti ketika jumlah iterasi=n telah\n",
        "dicapai."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GynkteueBhbg"
      },
      "source": [
        "def gradient_descent_1(X, y, iterasi, learning_rate = 0.01):\n",
        "\n",
        "  jumlah_variabel = X.shape[1]                # array numpy dengan 1 baris dan sejumla\n",
        "                                              # Contoh: X_array([[1,2], [3,4], [5,5],\n",
        "  bpoly = np.ones(shape=(jumlah_variabel))    # b1, b2, ... b(jumlah variabel)\n",
        "  b0 = 0                                      # b0 atau bias\n",
        "  n = X.shape[0]                              # jumlah baris data X\n",
        "  cost_list = []                              # list untuk menampung nilai cost setiap\n",
        "  iterasi_list = []                           # list untuk menampung nilai n iterasi(1\n",
        "  b_list=[]                                   # list untuk menampung nilai parameter r\n",
        "                                              # setiap iterasi\n",
        "  # Program akan berjalan hingga sejumlah iterasi=n dicapai\n",
        "  for i in range(iterasi):\n",
        "      y_pred = np.dot(bpoly, X.T) + b0           # Menghitung y_pred pada setiap iterasi\n",
        "      bpoly_grad = -(2/n)*(X.T.dot(y-y_pred))    # Menghitung perubahan/gradien bpoly set\n",
        "      b0_grad = -(2/n)*np.sum(y-y_pred)          # Menghitung perubahan/gradien b0 setiap\n",
        "      bpoly = bpoly - learning_rate * bpoly_grad # Memperbaharui bpoly setiap iterasi\n",
        "      b0 = b0 - learning_rate * b0_grad          # Memperbaharui bpoly setiap iterasi\n",
        "\n",
        "      # Menyimpan parameter b dalam list tunggal\n",
        "      bp=[]\n",
        "      for jv in range(jumlah_variabel):\n",
        "        bp1=bpoly[jv]\n",
        "        bp.append(bp1)\n",
        "      b=[b0]+bp\n",
        "      cost = np.mean(np.square(y-y_pred))        # MSE (Mean Squared Error)\n",
        "\n",
        "      cost_list.append(cost)                     # Menyimpan nilai cost setiap iterasi\n",
        "\n",
        "      iterasi_list.append(i)                     # Menyimpan nilai iterasi setiap iterasi\n",
        "      b_list.append(b)                           # Menyimpan nilai parameter b setiap ite\n",
        "  return bpoly, b0, cost, b_list, cost_list, iterasi_list # Ouput\n",
        "\n",
        "  bpoly, b0, cost, b_list, cost_list, iterasi_list = gradient_descent_1(X_train, y_train, iterasi_list, learning_rate = 0.01)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPZ3PZIlE99X"
      },
      "source": [
        "plt.xlabel(\"Iterasi\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.title(\"Cost Vs Iterasi\")\n",
        "plt.plot(iterasi_list,cost_list, color='red', label='Eror')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0YlmRYDFHWW"
      },
      "source": [
        "**Implementasi Pada Real Data**\n",
        "\n",
        "Untuk implementasi pada data real, kita akan menggunakan data dataset yang sama dengan sebelumnya.\n",
        "Untuk variabel x adalah ( Head Size(cm^3) ) sedangkan untuk variabel y adalah ( Brain Weight(grams) )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8ZCD3LBIFTfX",
        "outputId": "31db655f-2b72-4914-ca3f-99bceb8958ce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/jokoeliyanto/Channel-Hobi-Data/main/Model%20Machine%20Learning%20dari%20Dasar(From%20Scratch)%20Python/Dataset/dataset_regresi_linear.csv')\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age Range</th>\n",
              "      <th>Head Size(cm^3)</th>\n",
              "      <th>Brain Weight(grams)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4512</td>\n",
              "      <td>1530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3738</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4261</td>\n",
              "      <td>1335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3777</td>\n",
              "      <td>1282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4177</td>\n",
              "      <td>1590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender  Age Range  Head Size(cm^3)  Brain Weight(grams)\n",
              "0       1          1             4512                 1530\n",
              "1       1          1             3738                 1297\n",
              "2       1          1             4261                 1335\n",
              "3       1          1             3777                 1282\n",
              "4       1          1             4177                 1590"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NjphUTFbtK"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "sx = preprocessing.MinMaxScaler()\n",
        "sy = preprocessing.MinMaxScaler()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKdaDckRFdyf"
      },
      "source": [
        "# Definisikan dan Normalisasi Variabel Input(X) dan Output(Y)\n",
        "X = sy.fit_transform(df['Head Size(cm^3)'].values.reshape(df.shape[0],1))\n",
        "Y = sy.fit_transform(df['Brain Weight(grams)'].values.reshape(df.shape[0],1))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsfKFSxnFgUZ"
      },
      "source": [
        "# Membagi data menjadi data training dan data testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYQG41h3FldP",
        "outputId": "f84f2f03-75bb-4a9a-91cd-9cf023e7ff3b"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.18944253]\n",
            " [0.17217563]\n",
            " [0.33645782]\n",
            " [0.4647262 ]\n",
            " [0.4227923 ]\n",
            " [0.71090281]\n",
            " [0.3325111 ]\n",
            " [0.27577701]\n",
            " [0.17316231]\n",
            " [0.26048347]\n",
            " [0.49679329]\n",
            " [0.10804144]\n",
            " [0.22200296]\n",
            " [0.33103108]\n",
            " [0.28465713]\n",
            " [0.3349778 ]\n",
            " [0.38332511]\n",
            " [0.58164776]\n",
            " [0.37148495]\n",
            " [0.71879625]\n",
            " [0.44301924]\n",
            " [0.33201776]\n",
            " [0.27084361]\n",
            " [0.76467686]\n",
            " [0.34287124]\n",
            " [0.64923532]\n",
            " [0.41341885]\n",
            " [0.2150962 ]\n",
            " [0.10705476]\n",
            " [0.61272817]\n",
            " [0.73408979]\n",
            " [0.52146029]\n",
            " [0.28712383]\n",
            " [1.        ]\n",
            " [0.52639369]\n",
            " [0.50074001]\n",
            " [0.56536754]\n",
            " [0.5772077 ]\n",
            " [0.425259  ]\n",
            " [0.48100641]\n",
            " [0.84065121]\n",
            " [0.43857918]\n",
            " [0.65663542]\n",
            " [0.63739517]\n",
            " [0.48495313]\n",
            " [0.5476073 ]\n",
            " [0.52935372]\n",
            " [0.63443513]\n",
            " [0.40848545]\n",
            " [0.55895412]\n",
            " [0.29057721]\n",
            " [0.44104588]\n",
            " [0.31573754]\n",
            " [0.48544647]\n",
            " [0.41736556]\n",
            " [0.38727183]\n",
            " [0.54859398]\n",
            " [0.64232856]\n",
            " [0.57770104]\n",
            " [0.42723236]\n",
            " [0.57128762]\n",
            " [0.48692649]\n",
            " [0.78342378]\n",
            " [0.52244697]\n",
            " [0.24370992]\n",
            " [0.52836704]\n",
            " [0.13270844]\n",
            " [0.84953133]\n",
            " [0.46669956]\n",
            " [0.7602368 ]\n",
            " [0.46817958]\n",
            " [0.58362111]\n",
            " [0.32609768]\n",
            " [0.53478046]\n",
            " [0.3127775 ]\n",
            " [0.35668476]\n",
            " [0.35323138]\n",
            " [0.65959546]\n",
            " [0.73211643]\n",
            " [0.47607301]\n",
            " [0.41983226]\n",
            " [0.38628515]\n",
            " [0.46077948]\n",
            " [0.58164776]\n",
            " [0.2150962 ]\n",
            " [0.27824371]\n",
            " [0.43117908]\n",
            " [0.88406512]\n",
            " [0.48347311]\n",
            " [0.52244697]\n",
            " [0.81943759]\n",
            " [0.45584608]\n",
            " [0.45436606]\n",
            " [0.5574741 ]\n",
            " [0.25308337]\n",
            " [0.39960533]\n",
            " [0.48840651]\n",
            " [0.35421806]\n",
            " [0.59694129]\n",
            " [0.38233843]\n",
            " [0.40059201]\n",
            " [0.21953626]\n",
            " [0.31179082]\n",
            " [0.52540701]\n",
            " [0.84361125]\n",
            " [0.59842131]\n",
            " [0.73014307]\n",
            " [0.07104095]\n",
            " [0.62111495]\n",
            " [0.25061667]\n",
            " [0.16674889]\n",
            " [0.47804637]\n",
            " [0.29501727]\n",
            " [0.27479033]\n",
            " [0.62802171]\n",
            " [0.60039467]\n",
            " [0.57030094]\n",
            " [0.53971386]\n",
            " [0.71336951]\n",
            " [0.30044401]\n",
            " [0.50222003]\n",
            " [0.3349778 ]\n",
            " [0.3325111 ]\n",
            " [0.78687716]\n",
            " [0.45781944]\n",
            " [0.65416872]\n",
            " [0.47952639]\n",
            " [0.36803157]\n",
            " [0.30291071]\n",
            " [0.4671929 ]\n",
            " [0.6625555 ]\n",
            " [0.38332511]\n",
            " [0.21608288]\n",
            " [0.6576221 ]\n",
            " [0.70942279]\n",
            " [0.36211149]\n",
            " [0.2274297 ]\n",
            " [0.32708436]\n",
            " [0.28219043]\n",
            " [0.29748397]\n",
            " [0.53083374]\n",
            " [0.41243217]\n",
            " [0.19930932]\n",
            " [0.4548594 ]\n",
            " [0.        ]\n",
            " [0.3300444 ]\n",
            " [0.6822891 ]\n",
            " [0.31475086]\n",
            " [0.22446966]\n",
            " [0.38135175]\n",
            " [0.26985693]\n",
            " [0.71780957]\n",
            " [0.41489887]\n",
            " [0.37395165]\n",
            " [0.26097681]\n",
            " [0.3325111 ]\n",
            " [0.23828318]\n",
            " [0.550074  ]\n",
            " [0.3078441 ]\n",
            " [0.38431179]\n",
            " [0.36063148]\n",
            " [0.24568328]\n",
            " [0.69116922]\n",
            " [0.31672422]\n",
            " [0.84015787]\n",
            " [0.17858905]\n",
            " [0.56043414]\n",
            " [0.50320671]\n",
            " [0.44153922]\n",
            " [0.49136655]\n",
            " [0.38085841]\n",
            " [0.47705969]\n",
            " [0.59940799]\n",
            " [0.4203256 ]\n",
            " [0.38776517]\n",
            " [0.25949679]\n",
            " [0.63542181]\n",
            " [0.33843118]\n",
            " [0.39812531]\n",
            " [0.65416872]\n",
            " [0.42427232]\n",
            " [0.62259497]\n",
            " [0.46423286]\n",
            " [0.02614702]\n",
            " [0.32165762]\n",
            " [0.13813518]\n",
            " [0.5821411 ]\n",
            " [0.21953626]\n",
            " [0.41983226]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PtctBpyFsh1",
        "outputId": "aa79ffc4-1655-42c8-8367-9eaade838ac9"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.18382353]\n",
            " [0.09852941]\n",
            " [0.38970588]\n",
            " [0.40441176]\n",
            " [0.42647059]\n",
            " [0.66176471]\n",
            " [0.35294118]\n",
            " [0.45588235]\n",
            " [0.18088235]\n",
            " [0.43382353]\n",
            " [0.75735294]\n",
            " [0.15441176]\n",
            " [0.32794118]\n",
            " [0.25      ]\n",
            " [0.38970588]\n",
            " [0.39852941]\n",
            " [0.59264706]\n",
            " [0.625     ]\n",
            " [0.41911765]\n",
            " [0.93382353]\n",
            " [0.49264706]\n",
            " [0.32352941]\n",
            " [0.42058824]\n",
            " [0.55882353]\n",
            " [0.52205882]\n",
            " [0.78676471]\n",
            " [0.39705882]\n",
            " [0.39705882]\n",
            " [0.16911765]\n",
            " [0.58088235]\n",
            " [0.83382353]\n",
            " [0.48088235]\n",
            " [0.30882353]\n",
            " [1.        ]\n",
            " [0.53382353]\n",
            " [0.58088235]\n",
            " [0.67647059]\n",
            " [0.52205882]\n",
            " [0.50735294]\n",
            " [0.52205882]\n",
            " [0.65441176]\n",
            " [0.375     ]\n",
            " [0.51617647]\n",
            " [0.65441176]\n",
            " [0.58088235]\n",
            " [0.42647059]\n",
            " [0.58088235]\n",
            " [0.51029412]\n",
            " [0.74264706]\n",
            " [0.61470588]\n",
            " [0.24264706]\n",
            " [0.33088235]\n",
            " [0.20588235]\n",
            " [0.38970588]\n",
            " [0.51617647]\n",
            " [0.53676471]\n",
            " [0.37205882]\n",
            " [0.77941176]\n",
            " [0.39558824]\n",
            " [0.43382353]\n",
            " [0.59117647]\n",
            " [0.41176471]\n",
            " [0.81029412]\n",
            " [0.83088235]\n",
            " [0.22794118]\n",
            " [0.44852941]\n",
            " [0.25735294]\n",
            " [0.55147059]\n",
            " [0.46323529]\n",
            " [0.55882353]\n",
            " [0.39264706]\n",
            " [0.55735294]\n",
            " [0.33823529]\n",
            " [0.90441176]\n",
            " [0.36617647]\n",
            " [0.56617647]\n",
            " [0.41176471]\n",
            " [0.70147059]\n",
            " [0.625     ]\n",
            " [0.58088235]\n",
            " [0.5       ]\n",
            " [0.41911765]\n",
            " [0.42205882]\n",
            " [0.575     ]\n",
            " [0.31617647]\n",
            " [0.42794118]\n",
            " [0.49264706]\n",
            " [0.84558824]\n",
            " [0.49264706]\n",
            " [0.30882353]\n",
            " [0.67647059]\n",
            " [0.50735294]\n",
            " [0.52352941]\n",
            " [0.67205882]\n",
            " [0.21911765]\n",
            " [0.43676471]\n",
            " [0.46323529]\n",
            " [0.49264706]\n",
            " [0.43676471]\n",
            " [0.38676471]\n",
            " [0.55882353]\n",
            " [0.41470588]\n",
            " [0.31617647]\n",
            " [0.65441176]\n",
            " [0.81617647]\n",
            " [0.52058824]\n",
            " [0.44264706]\n",
            " [0.08382353]\n",
            " [0.54264706]\n",
            " [0.41176471]\n",
            " [0.24264706]\n",
            " [0.49264706]\n",
            " [0.34852941]\n",
            " [0.22058824]\n",
            " [0.625     ]\n",
            " [0.50735294]\n",
            " [0.93088235]\n",
            " [0.37058824]\n",
            " [0.88970588]\n",
            " [0.26470588]\n",
            " [0.50294118]\n",
            " [0.32058824]\n",
            " [0.42352941]\n",
            " [0.83823529]\n",
            " [0.44852941]\n",
            " [0.72794118]\n",
            " [0.51470588]\n",
            " [0.49558824]\n",
            " [0.41323529]\n",
            " [0.52205882]\n",
            " [0.63970588]\n",
            " [0.47794118]\n",
            " [0.21323529]\n",
            " [0.525     ]\n",
            " [0.70147059]\n",
            " [0.52205882]\n",
            " [0.32352941]\n",
            " [0.49264706]\n",
            " [0.17647059]\n",
            " [0.43235294]\n",
            " [0.70147059]\n",
            " [0.43382353]\n",
            " [0.30882353]\n",
            " [0.36764706]\n",
            " [0.        ]\n",
            " [0.25735294]\n",
            " [0.60147059]\n",
            " [0.34558824]\n",
            " [0.36029412]\n",
            " [0.41911765]\n",
            " [0.42352941]\n",
            " [0.68382353]\n",
            " [0.25294118]\n",
            " [0.46323529]\n",
            " [0.47647059]\n",
            " [0.38235294]\n",
            " [0.33088235]\n",
            " [0.52941176]\n",
            " [0.38970588]\n",
            " [0.47058824]\n",
            " [0.56617647]\n",
            " [0.15441176]\n",
            " [0.625     ]\n",
            " [0.34264706]\n",
            " [0.80882353]\n",
            " [0.33088235]\n",
            " [0.69852941]\n",
            " [0.47794118]\n",
            " [0.58088235]\n",
            " [0.50735294]\n",
            " [0.43382353]\n",
            " [0.58823529]\n",
            " [0.55147059]\n",
            " [0.46323529]\n",
            " [0.47794118]\n",
            " [0.33088235]\n",
            " [0.75441176]\n",
            " [0.38970588]\n",
            " [0.61764706]\n",
            " [0.48823529]\n",
            " [0.53676471]\n",
            " [0.61764706]\n",
            " [0.53676471]\n",
            " [0.17794118]\n",
            " [0.29264706]\n",
            " [0.19852941]\n",
            " [0.46323529]\n",
            " [0.38235294]\n",
            " [0.53088235]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B22dO82ZF0XF",
        "outputId": "bbef8ff0-9ec1-4092-e215-a3039f3b04ed"
      },
      "source": [
        "y_train_reshape=y_train.reshape(y_train.shape[0],)\n",
        "y_train_reshape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.18382353, 0.09852941, 0.38970588, 0.40441176, 0.42647059,\n",
              "       0.66176471, 0.35294118, 0.45588235, 0.18088235, 0.43382353,\n",
              "       0.75735294, 0.15441176, 0.32794118, 0.25      , 0.38970588,\n",
              "       0.39852941, 0.59264706, 0.625     , 0.41911765, 0.93382353,\n",
              "       0.49264706, 0.32352941, 0.42058824, 0.55882353, 0.52205882,\n",
              "       0.78676471, 0.39705882, 0.39705882, 0.16911765, 0.58088235,\n",
              "       0.83382353, 0.48088235, 0.30882353, 1.        , 0.53382353,\n",
              "       0.58088235, 0.67647059, 0.52205882, 0.50735294, 0.52205882,\n",
              "       0.65441176, 0.375     , 0.51617647, 0.65441176, 0.58088235,\n",
              "       0.42647059, 0.58088235, 0.51029412, 0.74264706, 0.61470588,\n",
              "       0.24264706, 0.33088235, 0.20588235, 0.38970588, 0.51617647,\n",
              "       0.53676471, 0.37205882, 0.77941176, 0.39558824, 0.43382353,\n",
              "       0.59117647, 0.41176471, 0.81029412, 0.83088235, 0.22794118,\n",
              "       0.44852941, 0.25735294, 0.55147059, 0.46323529, 0.55882353,\n",
              "       0.39264706, 0.55735294, 0.33823529, 0.90441176, 0.36617647,\n",
              "       0.56617647, 0.41176471, 0.70147059, 0.625     , 0.58088235,\n",
              "       0.5       , 0.41911765, 0.42205882, 0.575     , 0.31617647,\n",
              "       0.42794118, 0.49264706, 0.84558824, 0.49264706, 0.30882353,\n",
              "       0.67647059, 0.50735294, 0.52352941, 0.67205882, 0.21911765,\n",
              "       0.43676471, 0.46323529, 0.49264706, 0.43676471, 0.38676471,\n",
              "       0.55882353, 0.41470588, 0.31617647, 0.65441176, 0.81617647,\n",
              "       0.52058824, 0.44264706, 0.08382353, 0.54264706, 0.41176471,\n",
              "       0.24264706, 0.49264706, 0.34852941, 0.22058824, 0.625     ,\n",
              "       0.50735294, 0.93088235, 0.37058824, 0.88970588, 0.26470588,\n",
              "       0.50294118, 0.32058824, 0.42352941, 0.83823529, 0.44852941,\n",
              "       0.72794118, 0.51470588, 0.49558824, 0.41323529, 0.52205882,\n",
              "       0.63970588, 0.47794118, 0.21323529, 0.525     , 0.70147059,\n",
              "       0.52205882, 0.32352941, 0.49264706, 0.17647059, 0.43235294,\n",
              "       0.70147059, 0.43382353, 0.30882353, 0.36764706, 0.        ,\n",
              "       0.25735294, 0.60147059, 0.34558824, 0.36029412, 0.41911765,\n",
              "       0.42352941, 0.68382353, 0.25294118, 0.46323529, 0.47647059,\n",
              "       0.38235294, 0.33088235, 0.52941176, 0.38970588, 0.47058824,\n",
              "       0.56617647, 0.15441176, 0.625     , 0.34264706, 0.80882353,\n",
              "       0.33088235, 0.69852941, 0.47794118, 0.58088235, 0.50735294,\n",
              "       0.43382353, 0.58823529, 0.55147059, 0.46323529, 0.47794118,\n",
              "       0.33088235, 0.75441176, 0.38970588, 0.61764706, 0.48823529,\n",
              "       0.53676471, 0.61764706, 0.53676471, 0.17794118, 0.29264706,\n",
              "       0.19852941, 0.46323529, 0.38235294, 0.53088235])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1_Bb4TcF26a"
      },
      "source": [
        "Berikut adalah mendefinisikan fungsi gradient descent yang menghasilkan output vektor dan dan nilai\n",
        "eror untuk setiap iterasi. Selanjutnya kita akan melakukan visualisasi berupa animasi yang menunjukkan\n",
        "perbaikan persamaan garis regresi linear untuk setiap iterasi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrnb_kILF5Gk"
      },
      "source": [
        "def gradient_descent_1(X, y, iterasi, learning_rate = 0.01):\n",
        "  jumlah_variabel = X.shape[1]                  # array numpy dengan 1 baris dan sejumla\n",
        "                                                  # Contoh: X_array([[1,2], [3,4], [5,5],\n",
        "  bpoly = np.ones(shape=(jumlah_variabel))      # b1, b2, ... b(jumlah variabel)\n",
        "  b0 = 0                                        # b0 atau bias\n",
        "  n = X.shape[0]                                # jumlah baris data X\n",
        "  cost_list = []                                # list untuk menampung nilai cost setiap\n",
        "  iterasi_list = []                             # list untuk menampung nilai n iterasi(1\n",
        "  b_list=[]                                     # list untuk menampung nilai parameter r\n",
        "                                                  # setiap iterasi\n",
        "                                                  # Program akan berjalan hingga sejumlah iterasi=n dicapai\n",
        "  for i in range(iterasi):\n",
        "    y_pred = np.dot(bpoly, X.T) + b0            # Menghitung y_pred pada setiap iterasi\n",
        "    bpoly_grad = -(2/n)*(X.T.dot(y-y_pred))     # Menghitung perubahan/gradien bpoly set\n",
        "    b0_grad = -(2/n)*np.sum(y-y_pred)           # Menghitung perubahan/gradien b0 setiap\n",
        "    bpoly = bpoly - learning_rate * bpoly_grad  # Memperbaharui bpoly setiap iterasi\n",
        "    b0 = b0 - learning_rate * b0_grad           # Memperbaharui bpoly setiap iterasi\n",
        "   \n",
        "    # Menyimpan parameter b dalam list tunggal\n",
        "    bp=[]\n",
        "    for jv in range(jumlah_variabel):\n",
        "      bp1=bpoly[jv]\n",
        "      bp.append(bp1)\n",
        "    b=[b0]+bp\n",
        "\n",
        "    cost = np.mean(np.square(y-y_pred))         # MSE (Mean Squared Error)\n",
        "\n",
        "    cost_list.append(cost)                      # Menyimpan nilai cost setiap iterasi\n",
        "      \n",
        "    iterasi_list.append(i)                      # Menyimpan nilai iterasi setiap iterasi\n",
        "    b_list.append(b)                            # Menyimpan nilai parameter b setiap iterasi\n",
        "  \n",
        "  return bpoly, b0, cost, b_list, cost_list, iterasi_list # Ouput"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtvb8-7cH4lj"
      },
      "source": [
        "**Evaluasi Model**\n",
        "\n",
        "Kita perlu mengukur tingkat ketepatan(akurasi) model yang telah diperoleh. Terdapat banyak metode untuk\n",
        "melakukan hal ini, namun pada artikel ini kita memilih menggunakan **Root Mean Square Error** dan **Koefisien\n",
        "Determinasi ($R^2$ Skor)**\n",
        " \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frAP5n4hIY4B"
      },
      "source": [
        "\\begin{align}\n",
        "RMSE= \\sqrt{  \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y_i})}\n",
        "\\end{align}\n",
        " \\\\\n",
        " \\\\\n",
        "$\\hat{y_i}$ adalah nilai hasil prediksi ke-i. Berikut adalah penulisan kode untuk RMSE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sewYuweWJ-x3"
      },
      "source": [
        "rmse = 0\n",
        "for i in range(len(X_test)):\n",
        "  y_pred = b_0 + bpoly * X_test[i]\n",
        "  rmse += (y_test[i] - y_pred)**2\n",
        "\n",
        "rmse = np.sqrt(rmse/len(X_test))\n",
        "print(rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Z4CNMcK49p"
      },
      "source": [
        "Selanjutnya, mari kita hitung nilai skor untuk mengukur tingkat akurasi dari model linear yang diperoleh,\n",
        "secara matematis dituliskan sebagai berikut:\n",
        "\n",
        "\\begin{align}\n",
        "R^2 = 1 - \\frac{SSE}{SST} = 1 - \\frac {\\sum(\\hat{y_i} - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}\n",
        "\\end{align}\n",
        "\n",
        " \\\\\n",
        "\n",
        "SSE adalah jumlah kuadrat galat sedangkan SST jumlah kuadrat total.\n",
        "\n",
        " \\\\\n",
        "$R^2$ skor biasanya memiliki nilai antara 0 hingga 1. Nilai ini juga bisa bernilai negatif jika model regresi benar-\n",
        "benar salah. Di bawah ini adalah kode pemrograman untuk menghitung $R^2$ skor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "DULQD2CmL_dl",
        "outputId": "6d296cf6-7132-4716-8efc-4e82b026c711"
      },
      "source": [
        "SST = 0\n",
        "SSE = 0\n",
        "y_pred= b0 + bpoly*X_test\n",
        "y_rata2 = np.mean(y_test)\n",
        "\n",
        "for i in range(len(X_test)) :\n",
        "  SST += (y_test[i] - y_rata2) ** 2\n",
        "  SSE += (y_test[i] - y_pred[i]) **2\n",
        "  \n",
        "score = 1- (SSE/SST)\n",
        "print(\"Koefisien Determinasi:\", score)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-d72e48442aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mb0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbpoly\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_rata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b0' is not defined"
          ]
        }
      ]
    }
  ]
}